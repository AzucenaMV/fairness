{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azucena/miniconda3/envs/fairenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_validate\n",
    "from fairlearn.datasets import fetch_adult\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import tqdm as notebook_tqdm\n",
    "from metrics import (\n",
    "    equality_opportunity_difference,\n",
    "    predictive_equality_difference,\n",
    "    predictive_parity_difference,\n",
    "    metrics,\n",
    "    average_absolute_odds_difference,\n",
    "    metric_evaluation, \n",
    "    get_metric_evaluation,\n",
    "    \n",
    ")\n",
    "from fairlearn.metrics import demographic_parity_difference\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "import dill\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, \n",
    "    confusion_matrix, \n",
    "    make_scorer, \n",
    "    accuracy_score, \n",
    "    recall_score, \n",
    "    matthews_corrcoef,\n",
    "    precision_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_objective(trial, data_dict, sensitive_col, preprocessor):\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"RF\", 'GBM','LGBM'])\n",
    "\n",
    "    if classifier_name == \"logit\":        \n",
    "        params = {\n",
    "            \"penalty\" : trial.suggest_categorical('logit_penalty', ['l1','l2']),\n",
    "            \"C\" : trial.suggest_float('logit_c', 0.001, 10),\n",
    "            \"max_iter\": 2000,\n",
    "            \"solver\" : 'saga'\n",
    "            }\n",
    "        classifier = LogisticRegression(**params)\n",
    "\n",
    "    elif classifier_name ==\"RF\":\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int(\"rf_n_estimators\", 100, 1000),\n",
    "            'criterion': trial.suggest_categorical(\"rf_criterion\", ['gini', 'entropy']),\n",
    "            'max_depth': trial.suggest_int(\"rf_max_depth\", 1, 4),\n",
    "            'min_samples_split': trial.suggest_float(\"rf_min_samples_split\", 0.01, 1),\n",
    "            }\n",
    "        classifier = RandomForestClassifier(**params)\n",
    "\n",
    "    elif classifier_name ==\"LGBM\":\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int(\"lgbm_n_estimators\", 20, 10000),\n",
    "            'num_leaves': trial.suggest_int(\"lgbm_num_leaves\", 10, 1000),\n",
    "            'max_depth': trial.suggest_int(\"lgbm_max_depth\", 2, 20),\n",
    "            'min_child_samples': trial.suggest_int(\"lgbm_min_child_samples\", 5, 300),\n",
    "            'learning_rate': trial.suggest_float('lgbm_learning_rate', 1e-5, 1e-2),\n",
    "            'boosting_type': trial.suggest_categorical(\"lgbm_boosting_type\", ['goss', 'gbdt'])\n",
    "            }\n",
    "        classifier = LGBMClassifier(**params)  \n",
    "\n",
    "    elif classifier_name ==\"GBM\":\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int(\"gbm_n_estimators\", 100, 1000), \n",
    "            'criterion': trial.suggest_categorical(\"gbm_criterion\", ['squared_error', 'friedman_mse']),\n",
    "            'max_depth': trial.suggest_int(\"gbm_max_depth\", 1, 4),\n",
    "            'min_samples_split': trial.suggest_int(\"gbm_min_samples_split\", 5, 300),\n",
    "            }\n",
    "        classifier = GradientBoostingClassifier(**params)            \n",
    "\n",
    "    else:\n",
    "        None\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"classifier\", classifier),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline.fit(data_dict['X_train'], data_dict['y_train'])\n",
    "    y_pred = pipeline.predict(data_dict['X_test'])\n",
    "    metrics = metric_evaluation(\n",
    "        y_true= data_dict['y_test'], \n",
    "        y_pred= y_pred, \n",
    "        sensitive_features=data_dict['X_test'][sensitive_col]\n",
    "        )\n",
    "    return classifier_name, metrics\n",
    "\n",
    "\n",
    "def get_default_metrics(metrics, data_dict, sensitive_col, preprocessor):\n",
    "    models = metrics['overall']['model_name'].unique()\n",
    "    classifier = {\n",
    "        'logit' : LogisticRegression(),\n",
    "        'GBM' : GradientBoostingClassifier(),\n",
    "        'LGBM' : LGBMClassifier(),\n",
    "        'RF' : RandomForestClassifier(),\n",
    "    }\n",
    "\n",
    "    metrics['default_overall'] = pd.DataFrame()\n",
    "    metrics['default_bygroup'] = pd.DataFrame()\n",
    "    for model in models:\n",
    "        clf = classifier[model]\n",
    "        pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"preprocessor\", preprocessor),\n",
    "                (\"classifier\", clf),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline.fit(data_dict['X_train'], data_dict['y_train'])\n",
    "        y_pred = pipeline.predict(data_dict['X_test'])\n",
    "        metric_frame = metric_evaluation(\n",
    "            y_true= data_dict['y_test'], \n",
    "            y_pred=y_pred, \n",
    "            sensitive_features=data_dict['X_test'][sensitive_col]\n",
    "        )\n",
    "        # Overall\n",
    "        fair_records = pd.DataFrame.from_records([get_metric_evaluation(metric_frame)])\n",
    "        new_metric_overall = pd.concat([fair_records, pd.DataFrame(metric_frame.overall).T], axis = 1)\n",
    "        new_metric_overall['model'] = model\n",
    "        metrics['default_overall'] = pd.concat([metrics['default_overall'], new_metric_overall])\n",
    "        # By group\n",
    "        new_metric_bygroup = metric_frame.by_group.reset_index()\n",
    "        new_metric_bygroup['model'] = model\n",
    "        metrics['default_bygroup'] = pd.concat([metrics['default_bygroup'], new_metric_bygroup])\n",
    "    return metrics\n",
    "\n",
    "def get_metrics(study, data_dict, sensitive_col, preprocessor):\n",
    "    metrics = {}\n",
    "    metrics['overall'] = pd.DataFrame()\n",
    "    metrics['bygroup'] = pd.DataFrame()\n",
    "    #metrics['fair_metric'] = study.user_attrs['fair_metric']\n",
    "    #metrics['model_metric'] = study.user_attrs['model_metric']\n",
    "    i = 1\n",
    "    for best_trial in study.best_trials:\n",
    "        if best_trial.values != [0,0]:\n",
    "            fair_value, model_value = best_trial.values\n",
    "            clf_name, metric = detailed_objective(best_trial, data_dict, sensitive_col, preprocessor)\n",
    "            # Overall\n",
    "            fair_records = pd.DataFrame.from_records([get_metric_evaluation(metric)])\n",
    "            new_metric_overall = pd.concat([fair_records, pd.DataFrame(metric.overall).T], axis = 1)\n",
    "            new_metric_overall['best_trial'] = i\n",
    "            new_metric_overall['fair_metric'] = fair_value\n",
    "            new_metric_overall['model_metric'] = model_value\n",
    "            new_metric_overall['model_name'] = clf_name\n",
    "            metrics['overall'] = pd.concat([metrics['overall'], new_metric_overall])\n",
    "            # By Groups\n",
    "            new_metric_bygroup = metric.by_group.reset_index()\n",
    "            new_metric_bygroup['best_trial'] = i\n",
    "            metrics['bygroup'] = pd.concat([metrics['bygroup'], new_metric_bygroup])\n",
    "            i += 1\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azucena/miniconda3/envs/fairenv/lib/python3.10/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n",
      "/home/azucena/miniconda3/envs/fairenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/azucena/miniconda3/envs/fairenv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"impute\", SimpleImputer()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    [\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "n_sim = 0\n",
    "sensitive_col = 'sex'\n",
    "file_name = 'results/sex/f1-ppv-models-motpe-succesivehalving-parallel-150trials-4sim.pkl'\n",
    "\n",
    "with open(file_name, 'rb') as in_strm:\n",
    "    results = dill.load(in_strm)\n",
    "\n",
    "sensitive_attribute = 'sex'\n",
    "sim_n = 1\n",
    "data = fetch_adult(as_frame=True)\n",
    "X_raw = data.data\n",
    "y = (data.target == \">50K\") * 1\n",
    "\n",
    "if sensitive_attribute == 'race':\n",
    "    mapping = {'White':'white','Black':'black','Asian-Pac-Islander':'others','Amer-Indian-Eskimo':'others','Other':'others'}\n",
    "    X_raw.loc[:,'race'] = X_raw['race'].map(mapping).astype(\"category\")\n",
    "\n",
    "perc = .5\n",
    "X_raw, y = resample(X_raw, y, n_samples=int(perc*X_raw.shape[0]), random_state = 123)  \n",
    "  \n",
    "(X_train, X_test, y_train, y_test) = train_test_split(\n",
    "    X_raw, y, test_size=0.8, stratify=y, random_state=sim_n\n",
    ")\n",
    "\n",
    "data_dict = {}\n",
    "data_dict['X_train'] = X_train.reset_index(drop=True)\n",
    "data_dict['X_test'] = X_test.reset_index(drop=True)\n",
    "data_dict['y_train'] = y_train.reset_index(drop=True)\n",
    "data_dict['y_test'] = y_test.reset_index(drop=True)\n",
    "\n",
    "study = results[0]\n",
    "metrics = get_metrics(study, data_dict, sensitive_col, preprocessor)\n",
    "metrics = get_default_metrics(metrics, data_dict, sensitive_col, preprocessor)\n",
    "metrics['file_name'] = file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['overall', 'bygroup', 'default_overall', 'default_bygroup', 'file_name'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object successfully saved to \"results/sex/f1-ppv-models-motpe-succesivehalving-parallel-150trials-4sim-metrics.pkl\"\n"
     ]
    }
   ],
   "source": [
    "file_name = 'results/sex/f1-ppv-models-motpe-succesivehalving-parallel-150trials-4sim.pkl'\n",
    "file_name = file_name[:-4] + '-metrics.pkl'\n",
    "with open(file_name, 'wb') as file:\n",
    "    dill.dump(metrics, file)\n",
    "    print(f'Object successfully saved to \"{file_name}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "0    NaN\n",
       "Name: model, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mapping = {\n",
    "    'LogisticRegression':'LR',\n",
    "    'RandomForestClassifier':'RF',\n",
    "    'GradientBoostingClassifier':'GBM',\n",
    "    'LGBMClassifier' : 'LGBM'}\n",
    "\n",
    "\n",
    "metrics['default_overall']['model'].map(model_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demographic parity</th>\n",
       "      <th>predictive parity</th>\n",
       "      <th>equality opportunity</th>\n",
       "      <th>predictive equality</th>\n",
       "      <th>average absolute odds</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>mcc</th>\n",
       "      <th>selection rate</th>\n",
       "      <th>false positive rate</th>\n",
       "      <th>true positive rate</th>\n",
       "      <th>false negative rate</th>\n",
       "      <th>true negative rate</th>\n",
       "      <th>count</th>\n",
       "      <th>best_trial</th>\n",
       "      <th>fair_metric</th>\n",
       "      <th>model_metric</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024310</td>\n",
       "      <td>0.996835</td>\n",
       "      <td>0.079727</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.039919</td>\n",
       "      <td>0.776322</td>\n",
       "      <td>0.996835</td>\n",
       "      <td>0.067250</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.227375</td>\n",
       "      <td>0.016174</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.067250</td>\n",
       "      <td>0.932750</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.129615</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.037206</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.767723</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.060844</td>\n",
       "      <td>0.154197</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.968617</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052761</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038655</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.091722</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.046082</td>\n",
       "      <td>0.791677</td>\n",
       "      <td>0.993569</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>0.232944</td>\n",
       "      <td>0.320185</td>\n",
       "      <td>0.031837</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>0.868061</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.211406</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028683</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.031614</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.015973</td>\n",
       "      <td>0.790039</td>\n",
       "      <td>0.994898</td>\n",
       "      <td>0.124893</td>\n",
       "      <td>0.221927</td>\n",
       "      <td>0.311580</td>\n",
       "      <td>0.030097</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.124893</td>\n",
       "      <td>0.875107</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.392168</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.036005</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.043393</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>0.796796</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.153928</td>\n",
       "      <td>0.266445</td>\n",
       "      <td>0.345902</td>\n",
       "      <td>0.037263</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.153928</td>\n",
       "      <td>0.846072</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.398623</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.027780</td>\n",
       "      <td>0.052258</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>0.029425</td>\n",
       "      <td>0.802631</td>\n",
       "      <td>0.923313</td>\n",
       "      <td>0.192784</td>\n",
       "      <td>0.318969</td>\n",
       "      <td>0.367547</td>\n",
       "      <td>0.050059</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.192784</td>\n",
       "      <td>0.807216</td>\n",
       "      <td>0.994951</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.006572</td>\n",
       "      <td>0.493216</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042162</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.010208</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.812510</td>\n",
       "      <td>0.976657</td>\n",
       "      <td>0.223313</td>\n",
       "      <td>0.363510</td>\n",
       "      <td>0.415684</td>\n",
       "      <td>0.054819</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.223313</td>\n",
       "      <td>0.776687</td>\n",
       "      <td>0.998317</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.472184</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.141611</td>\n",
       "      <td>0.086868</td>\n",
       "      <td>0.115178</td>\n",
       "      <td>0.044837</td>\n",
       "      <td>0.080007</td>\n",
       "      <td>0.854225</td>\n",
       "      <td>0.827156</td>\n",
       "      <td>0.495517</td>\n",
       "      <td>0.619760</td>\n",
       "      <td>0.563461</td>\n",
       "      <td>0.143625</td>\n",
       "      <td>0.032653</td>\n",
       "      <td>0.495517</td>\n",
       "      <td>0.504483</td>\n",
       "      <td>0.967347</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.039348</td>\n",
       "      <td>0.635345</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.120669</td>\n",
       "      <td>0.056145</td>\n",
       "      <td>0.092362</td>\n",
       "      <td>0.030163</td>\n",
       "      <td>0.061262</td>\n",
       "      <td>0.852024</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.455807</td>\n",
       "      <td>0.596285</td>\n",
       "      <td>0.555305</td>\n",
       "      <td>0.126785</td>\n",
       "      <td>0.023026</td>\n",
       "      <td>0.455807</td>\n",
       "      <td>0.544193</td>\n",
       "      <td>0.976974</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.021963</td>\n",
       "      <td>0.618610</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.184179</td>\n",
       "      <td>0.063885</td>\n",
       "      <td>0.138032</td>\n",
       "      <td>0.071359</td>\n",
       "      <td>0.104696</td>\n",
       "      <td>0.864155</td>\n",
       "      <td>0.774324</td>\n",
       "      <td>0.611657</td>\n",
       "      <td>0.683445</td>\n",
       "      <td>0.605222</td>\n",
       "      <td>0.189384</td>\n",
       "      <td>0.056218</td>\n",
       "      <td>0.611657</td>\n",
       "      <td>0.388343</td>\n",
       "      <td>0.943782</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.049580</td>\n",
       "      <td>0.704688</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.196430</td>\n",
       "      <td>0.067135</td>\n",
       "      <td>0.145749</td>\n",
       "      <td>0.082776</td>\n",
       "      <td>0.114262</td>\n",
       "      <td>0.861801</td>\n",
       "      <td>0.752932</td>\n",
       "      <td>0.630444</td>\n",
       "      <td>0.686265</td>\n",
       "      <td>0.602416</td>\n",
       "      <td>0.200747</td>\n",
       "      <td>0.065239</td>\n",
       "      <td>0.630444</td>\n",
       "      <td>0.369556</td>\n",
       "      <td>0.934761</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.052571</td>\n",
       "      <td>0.711351</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088155</td>\n",
       "      <td>0.049605</td>\n",
       "      <td>0.052525</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.839945</td>\n",
       "      <td>0.912560</td>\n",
       "      <td>0.367635</td>\n",
       "      <td>0.524121</td>\n",
       "      <td>0.515286</td>\n",
       "      <td>0.096586</td>\n",
       "      <td>0.011109</td>\n",
       "      <td>0.367635</td>\n",
       "      <td>0.632365</td>\n",
       "      <td>0.988891</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>0.514874</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.164985</td>\n",
       "      <td>0.051462</td>\n",
       "      <td>0.133908</td>\n",
       "      <td>0.056247</td>\n",
       "      <td>0.095078</td>\n",
       "      <td>0.862210</td>\n",
       "      <td>0.799819</td>\n",
       "      <td>0.567250</td>\n",
       "      <td>0.663752</td>\n",
       "      <td>0.593780</td>\n",
       "      <td>0.170036</td>\n",
       "      <td>0.044772</td>\n",
       "      <td>0.567250</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>0.955228</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.039683</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.091633</td>\n",
       "      <td>0.026325</td>\n",
       "      <td>0.054717</td>\n",
       "      <td>0.017479</td>\n",
       "      <td>0.036098</td>\n",
       "      <td>0.839689</td>\n",
       "      <td>0.890735</td>\n",
       "      <td>0.377669</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>0.512923</td>\n",
       "      <td>0.101653</td>\n",
       "      <td>0.014610</td>\n",
       "      <td>0.377669</td>\n",
       "      <td>0.622331</td>\n",
       "      <td>0.985390</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.011271</td>\n",
       "      <td>0.539128</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.108260</td>\n",
       "      <td>0.043261</td>\n",
       "      <td>0.085268</td>\n",
       "      <td>0.023938</td>\n",
       "      <td>0.054603</td>\n",
       "      <td>0.846343</td>\n",
       "      <td>0.875782</td>\n",
       "      <td>0.418446</td>\n",
       "      <td>0.566310</td>\n",
       "      <td>0.535847</td>\n",
       "      <td>0.114552</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.418446</td>\n",
       "      <td>0.581554</td>\n",
       "      <td>0.981283</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.016921</td>\n",
       "      <td>0.589778</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.203385</td>\n",
       "      <td>0.010185</td>\n",
       "      <td>0.118353</td>\n",
       "      <td>0.086242</td>\n",
       "      <td>0.102298</td>\n",
       "      <td>0.865179</td>\n",
       "      <td>0.734661</td>\n",
       "      <td>0.685098</td>\n",
       "      <td>0.709015</td>\n",
       "      <td>0.622060</td>\n",
       "      <td>0.223576</td>\n",
       "      <td>0.078031</td>\n",
       "      <td>0.685098</td>\n",
       "      <td>0.314902</td>\n",
       "      <td>0.921969</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.055012</td>\n",
       "      <td>0.764921</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>0.784153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099701</td>\n",
       "      <td>0.181324</td>\n",
       "      <td>0.278665</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099701</td>\n",
       "      <td>0.900299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.298484</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.068367</td>\n",
       "      <td>0.026821</td>\n",
       "      <td>0.017659</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>0.012727</td>\n",
       "      <td>0.831448</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.316396</td>\n",
       "      <td>0.473709</td>\n",
       "      <td>0.486843</td>\n",
       "      <td>0.080514</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>0.316396</td>\n",
       "      <td>0.683604</td>\n",
       "      <td>0.993873</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.471810</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057346</td>\n",
       "      <td>0.006960</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>0.825869</td>\n",
       "      <td>0.969941</td>\n",
       "      <td>0.282451</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.468568</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.282451</td>\n",
       "      <td>0.717549</td>\n",
       "      <td>0.997240</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.417735</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054103</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>0.010189</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.822337</td>\n",
       "      <td>0.972720</td>\n",
       "      <td>0.266439</td>\n",
       "      <td>0.418301</td>\n",
       "      <td>0.455159</td>\n",
       "      <td>0.065670</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.266439</td>\n",
       "      <td>0.733561</td>\n",
       "      <td>0.997644</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.427776</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.177417</td>\n",
       "      <td>0.018572</td>\n",
       "      <td>0.141384</td>\n",
       "      <td>0.067336</td>\n",
       "      <td>0.104360</td>\n",
       "      <td>0.858320</td>\n",
       "      <td>0.763476</td>\n",
       "      <td>0.592656</td>\n",
       "      <td>0.667308</td>\n",
       "      <td>0.586606</td>\n",
       "      <td>0.186108</td>\n",
       "      <td>0.057901</td>\n",
       "      <td>0.592656</td>\n",
       "      <td>0.407344</td>\n",
       "      <td>0.942099</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.041186</td>\n",
       "      <td>0.696462</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178495</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>0.142298</td>\n",
       "      <td>0.068109</td>\n",
       "      <td>0.105203</td>\n",
       "      <td>0.858474</td>\n",
       "      <td>0.762661</td>\n",
       "      <td>0.594791</td>\n",
       "      <td>0.668346</td>\n",
       "      <td>0.587374</td>\n",
       "      <td>0.186979</td>\n",
       "      <td>0.058372</td>\n",
       "      <td>0.594791</td>\n",
       "      <td>0.405209</td>\n",
       "      <td>0.941628</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.042791</td>\n",
       "      <td>0.702810</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   demographic parity  predictive parity  equality opportunity   \n",
       "0            0.024310           0.996835              0.079727  \\\n",
       "0            0.011385           0.993243              0.037206   \n",
       "0            0.038655           0.006873              0.091722   \n",
       "0            0.028683           0.005814              0.031614   \n",
       "0            0.036005           0.002134              0.043393   \n",
       "0            0.048800           0.027780              0.052258   \n",
       "0            0.042162           0.006250              0.010208   \n",
       "0            0.141611           0.086868              0.115178   \n",
       "0            0.120669           0.056145              0.092362   \n",
       "0            0.184179           0.063885              0.138032   \n",
       "0            0.196430           0.067135              0.145749   \n",
       "0            0.088155           0.049605              0.052525   \n",
       "0            0.164985           0.051462              0.133908   \n",
       "0            0.091633           0.026325              0.054717   \n",
       "0            0.108260           0.043261              0.085268   \n",
       "0            0.203385           0.010185              0.118353   \n",
       "0            0.021673           0.000000              0.017922   \n",
       "0            0.068367           0.026821              0.017659   \n",
       "0            0.057346           0.006960              0.008146   \n",
       "0            0.054103           0.001775              0.010189   \n",
       "0            0.177417           0.018572              0.141384   \n",
       "0            0.178495           0.020057              0.142298   \n",
       "\n",
       "   predictive equality  average absolute odds  accuracy  precision    recall   \n",
       "0             0.000111               0.039919  0.776322   0.996835  0.067250  \\\n",
       "0             0.000111               0.018658  0.767723   0.993243  0.031383   \n",
       "0             0.000442               0.046082  0.791677   0.993569  0.131939   \n",
       "0             0.000332               0.015973  0.790039   0.994898  0.124893   \n",
       "0             0.000491               0.021942  0.796796   0.990385  0.153928   \n",
       "0             0.006592               0.029425  0.802631   0.923313  0.192784   \n",
       "0             0.001349               0.005778  0.812510   0.976657  0.223313   \n",
       "0             0.044837               0.080007  0.854225   0.827156  0.495517   \n",
       "0             0.030163               0.061262  0.852024   0.861930  0.455807   \n",
       "0             0.071359               0.104696  0.864155   0.774324  0.611657   \n",
       "0             0.082776               0.114262  0.861801   0.752932  0.630444   \n",
       "0             0.015125               0.033825  0.839945   0.912560  0.367635   \n",
       "0             0.056247               0.095078  0.862210   0.799819  0.567250   \n",
       "0             0.017479               0.036098  0.839689   0.890735  0.377669   \n",
       "0             0.023938               0.054603  0.846343   0.875782  0.418446   \n",
       "0             0.086242               0.102298  0.865179   0.734661  0.685098   \n",
       "0             0.000000               0.008961  0.784153   1.000000  0.099701   \n",
       "0             0.007795               0.012727  0.831448   0.942149  0.316396   \n",
       "0             0.003117               0.005632  0.825869   0.969941  0.282451   \n",
       "0             0.002454               0.006322  0.822337   0.972720  0.266439   \n",
       "0             0.067336               0.104360  0.858320   0.763476  0.592656   \n",
       "0             0.068109               0.105203  0.858474   0.762661  0.594791   \n",
       "\n",
       "   f1 score       mcc  selection rate  false positive rate   \n",
       "0  0.126000  0.227375        0.016174             0.000067  \\\n",
       "0  0.060844  0.154197        0.007575             0.000067   \n",
       "0  0.232944  0.320185        0.031837             0.000269   \n",
       "0  0.221927  0.311580        0.030097             0.000202   \n",
       "0  0.266445  0.345902        0.037263             0.000471   \n",
       "0  0.318969  0.367547        0.050059             0.005049   \n",
       "0  0.363510  0.415684        0.054819             0.001683   \n",
       "0  0.619760  0.563461        0.143625             0.032653   \n",
       "0  0.596285  0.555305        0.126785             0.023026   \n",
       "0  0.683445  0.605222        0.189384             0.056218   \n",
       "0  0.686265  0.602416        0.200747             0.065239   \n",
       "0  0.524121  0.515286        0.096586             0.011109   \n",
       "0  0.663752  0.593780        0.170036             0.044772   \n",
       "0  0.530435  0.512923        0.101653             0.014610   \n",
       "0  0.566310  0.535847        0.114552             0.018717   \n",
       "0  0.709015  0.622060        0.223576             0.078031   \n",
       "0  0.181324  0.278665        0.023903             0.000000   \n",
       "0  0.473709  0.486843        0.080514             0.006127   \n",
       "0  0.437500  0.468568        0.069816             0.002760   \n",
       "0  0.418301  0.455159        0.065670             0.002356   \n",
       "0  0.667308  0.586606        0.186108             0.057901   \n",
       "0  0.668346  0.587374        0.186979             0.058372   \n",
       "\n",
       "   true positive rate  false negative rate  true negative rate    count   \n",
       "0            0.067250             0.932750            0.999933  19537.0  \\\n",
       "0            0.031383             0.968617            0.999933  19537.0   \n",
       "0            0.131939             0.868061            0.999731  19537.0   \n",
       "0            0.124893             0.875107            0.999798  19537.0   \n",
       "0            0.153928             0.846072            0.999529  19537.0   \n",
       "0            0.192784             0.807216            0.994951  19537.0   \n",
       "0            0.223313             0.776687            0.998317  19537.0   \n",
       "0            0.495517             0.504483            0.967347  19537.0   \n",
       "0            0.455807             0.544193            0.976974  19537.0   \n",
       "0            0.611657             0.388343            0.943782  19537.0   \n",
       "0            0.630444             0.369556            0.934761  19537.0   \n",
       "0            0.367635             0.632365            0.988891  19537.0   \n",
       "0            0.567250             0.432750            0.955228  19537.0   \n",
       "0            0.377669             0.622331            0.985390  19537.0   \n",
       "0            0.418446             0.581554            0.981283  19537.0   \n",
       "0            0.685098             0.314902            0.921969  19537.0   \n",
       "0            0.099701             0.900299            1.000000  19537.0   \n",
       "0            0.316396             0.683604            0.993873  19537.0   \n",
       "0            0.282451             0.717549            0.997240  19537.0   \n",
       "0            0.266439             0.733561            0.997644  19537.0   \n",
       "0            0.592656             0.407344            0.942099  19537.0   \n",
       "0            0.594791             0.405209            0.941628  19537.0   \n",
       "\n",
       "   best_trial  fair_metric  model_metric model_name  \n",
       "0           1     0.000111      0.129615         RF  \n",
       "0           2     0.000000      0.052761         RF  \n",
       "0           3     0.000219      0.211406         RF  \n",
       "0           4     0.000726      0.392168       LGBM  \n",
       "0           5     0.000812      0.398623       LGBM  \n",
       "0           6     0.006572      0.493216       LGBM  \n",
       "0           7     0.004248      0.472184       LGBM  \n",
       "0           8     0.039348      0.635345       LGBM  \n",
       "0           9     0.021963      0.618610       LGBM  \n",
       "0          10     0.049580      0.704688       LGBM  \n",
       "0          11     0.052571      0.711351       LGBM  \n",
       "0          12     0.006675      0.514874       LGBM  \n",
       "0          13     0.039683      0.667200       LGBM  \n",
       "0          14     0.011271      0.539128       LGBM  \n",
       "0          15     0.016921      0.589778       LGBM  \n",
       "0          16     0.055012      0.764921       LGBM  \n",
       "0          17     0.000328      0.298484       LGBM  \n",
       "0          18     0.003929      0.471810       LGBM  \n",
       "0          19     0.000948      0.417735       LGBM  \n",
       "0          20     0.001751      0.427776       LGBM  \n",
       "0          21     0.041186      0.696462       LGBM  \n",
       "0          22     0.042791      0.702810       LGBM  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_metrics_sorted = df_metrics.sort_values(['train_fair'])\n",
    "#new_index = df_metrics_sorted.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics['overall'] = metrics['overall'].sort_values(['fair_metric']).reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['overall'].loc[metrics['overall'].index == 3,'best_trial'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demographic parity</th>\n",
       "      <th>predictive parity</th>\n",
       "      <th>equality opportunity</th>\n",
       "      <th>predictive equality</th>\n",
       "      <th>average absolute odds</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1 score</th>\n",
       "      <th>mcc</th>\n",
       "      <th>selection rate</th>\n",
       "      <th>false positive rate</th>\n",
       "      <th>true positive rate</th>\n",
       "      <th>false negative rate</th>\n",
       "      <th>true negative rate</th>\n",
       "      <th>count</th>\n",
       "      <th>best_trial</th>\n",
       "      <th>fair_metric</th>\n",
       "      <th>model_metric</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.037206</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.767723</td>\n",
       "      <td>0.993243</td>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.060844</td>\n",
       "      <td>0.154197</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.031383</td>\n",
       "      <td>0.968617</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052761</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.024310</td>\n",
       "      <td>0.996835</td>\n",
       "      <td>0.079727</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.039919</td>\n",
       "      <td>0.776322</td>\n",
       "      <td>0.996835</td>\n",
       "      <td>0.067250</td>\n",
       "      <td>0.126000</td>\n",
       "      <td>0.227375</td>\n",
       "      <td>0.016174</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.067250</td>\n",
       "      <td>0.932750</td>\n",
       "      <td>0.999933</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.129615</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038655</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.091722</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.046082</td>\n",
       "      <td>0.791677</td>\n",
       "      <td>0.993569</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>0.232944</td>\n",
       "      <td>0.320185</td>\n",
       "      <td>0.031837</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.131939</td>\n",
       "      <td>0.868061</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.211406</td>\n",
       "      <td>RF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>0.784153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099701</td>\n",
       "      <td>0.181324</td>\n",
       "      <td>0.278665</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099701</td>\n",
       "      <td>0.900299</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.298484</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028683</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.031614</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.015973</td>\n",
       "      <td>0.790039</td>\n",
       "      <td>0.994898</td>\n",
       "      <td>0.124893</td>\n",
       "      <td>0.221927</td>\n",
       "      <td>0.311580</td>\n",
       "      <td>0.030097</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.124893</td>\n",
       "      <td>0.875107</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.392168</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.036005</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>0.043393</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>0.796796</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.153928</td>\n",
       "      <td>0.266445</td>\n",
       "      <td>0.345902</td>\n",
       "      <td>0.037263</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.153928</td>\n",
       "      <td>0.846072</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.398623</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.057346</td>\n",
       "      <td>0.006960</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>0.825869</td>\n",
       "      <td>0.969941</td>\n",
       "      <td>0.282451</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.468568</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.282451</td>\n",
       "      <td>0.717549</td>\n",
       "      <td>0.997240</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.417735</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.054103</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>0.010189</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>0.822337</td>\n",
       "      <td>0.972720</td>\n",
       "      <td>0.266439</td>\n",
       "      <td>0.418301</td>\n",
       "      <td>0.455159</td>\n",
       "      <td>0.065670</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.266439</td>\n",
       "      <td>0.733561</td>\n",
       "      <td>0.997644</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.427776</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.068367</td>\n",
       "      <td>0.026821</td>\n",
       "      <td>0.017659</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>0.012727</td>\n",
       "      <td>0.831448</td>\n",
       "      <td>0.942149</td>\n",
       "      <td>0.316396</td>\n",
       "      <td>0.473709</td>\n",
       "      <td>0.486843</td>\n",
       "      <td>0.080514</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>0.316396</td>\n",
       "      <td>0.683604</td>\n",
       "      <td>0.993873</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.471810</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.042162</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.010208</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>0.812510</td>\n",
       "      <td>0.976657</td>\n",
       "      <td>0.223313</td>\n",
       "      <td>0.363510</td>\n",
       "      <td>0.415684</td>\n",
       "      <td>0.054819</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.223313</td>\n",
       "      <td>0.776687</td>\n",
       "      <td>0.998317</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.472184</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.027780</td>\n",
       "      <td>0.052258</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>0.029425</td>\n",
       "      <td>0.802631</td>\n",
       "      <td>0.923313</td>\n",
       "      <td>0.192784</td>\n",
       "      <td>0.318969</td>\n",
       "      <td>0.367547</td>\n",
       "      <td>0.050059</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.192784</td>\n",
       "      <td>0.807216</td>\n",
       "      <td>0.994951</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.006572</td>\n",
       "      <td>0.493216</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.088155</td>\n",
       "      <td>0.049605</td>\n",
       "      <td>0.052525</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.033825</td>\n",
       "      <td>0.839945</td>\n",
       "      <td>0.912560</td>\n",
       "      <td>0.367635</td>\n",
       "      <td>0.524121</td>\n",
       "      <td>0.515286</td>\n",
       "      <td>0.096586</td>\n",
       "      <td>0.011109</td>\n",
       "      <td>0.367635</td>\n",
       "      <td>0.632365</td>\n",
       "      <td>0.988891</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>0.514874</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.091633</td>\n",
       "      <td>0.026325</td>\n",
       "      <td>0.054717</td>\n",
       "      <td>0.017479</td>\n",
       "      <td>0.036098</td>\n",
       "      <td>0.839689</td>\n",
       "      <td>0.890735</td>\n",
       "      <td>0.377669</td>\n",
       "      <td>0.530435</td>\n",
       "      <td>0.512923</td>\n",
       "      <td>0.101653</td>\n",
       "      <td>0.014610</td>\n",
       "      <td>0.377669</td>\n",
       "      <td>0.622331</td>\n",
       "      <td>0.985390</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.011271</td>\n",
       "      <td>0.539128</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.108260</td>\n",
       "      <td>0.043261</td>\n",
       "      <td>0.085268</td>\n",
       "      <td>0.023938</td>\n",
       "      <td>0.054603</td>\n",
       "      <td>0.846343</td>\n",
       "      <td>0.875782</td>\n",
       "      <td>0.418446</td>\n",
       "      <td>0.566310</td>\n",
       "      <td>0.535847</td>\n",
       "      <td>0.114552</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.418446</td>\n",
       "      <td>0.581554</td>\n",
       "      <td>0.981283</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.016921</td>\n",
       "      <td>0.589778</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.120669</td>\n",
       "      <td>0.056145</td>\n",
       "      <td>0.092362</td>\n",
       "      <td>0.030163</td>\n",
       "      <td>0.061262</td>\n",
       "      <td>0.852024</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.455807</td>\n",
       "      <td>0.596285</td>\n",
       "      <td>0.555305</td>\n",
       "      <td>0.126785</td>\n",
       "      <td>0.023026</td>\n",
       "      <td>0.455807</td>\n",
       "      <td>0.544193</td>\n",
       "      <td>0.976974</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.021963</td>\n",
       "      <td>0.618610</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.141611</td>\n",
       "      <td>0.086868</td>\n",
       "      <td>0.115178</td>\n",
       "      <td>0.044837</td>\n",
       "      <td>0.080007</td>\n",
       "      <td>0.854225</td>\n",
       "      <td>0.827156</td>\n",
       "      <td>0.495517</td>\n",
       "      <td>0.619760</td>\n",
       "      <td>0.563461</td>\n",
       "      <td>0.143625</td>\n",
       "      <td>0.032653</td>\n",
       "      <td>0.495517</td>\n",
       "      <td>0.504483</td>\n",
       "      <td>0.967347</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.039348</td>\n",
       "      <td>0.635345</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.164985</td>\n",
       "      <td>0.051462</td>\n",
       "      <td>0.133908</td>\n",
       "      <td>0.056247</td>\n",
       "      <td>0.095078</td>\n",
       "      <td>0.862210</td>\n",
       "      <td>0.799819</td>\n",
       "      <td>0.567250</td>\n",
       "      <td>0.663752</td>\n",
       "      <td>0.593780</td>\n",
       "      <td>0.170036</td>\n",
       "      <td>0.044772</td>\n",
       "      <td>0.567250</td>\n",
       "      <td>0.432750</td>\n",
       "      <td>0.955228</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.039683</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.177417</td>\n",
       "      <td>0.018572</td>\n",
       "      <td>0.141384</td>\n",
       "      <td>0.067336</td>\n",
       "      <td>0.104360</td>\n",
       "      <td>0.858320</td>\n",
       "      <td>0.763476</td>\n",
       "      <td>0.592656</td>\n",
       "      <td>0.667308</td>\n",
       "      <td>0.586606</td>\n",
       "      <td>0.186108</td>\n",
       "      <td>0.057901</td>\n",
       "      <td>0.592656</td>\n",
       "      <td>0.407344</td>\n",
       "      <td>0.942099</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>21</td>\n",
       "      <td>0.041186</td>\n",
       "      <td>0.696462</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.178495</td>\n",
       "      <td>0.020057</td>\n",
       "      <td>0.142298</td>\n",
       "      <td>0.068109</td>\n",
       "      <td>0.105203</td>\n",
       "      <td>0.858474</td>\n",
       "      <td>0.762661</td>\n",
       "      <td>0.594791</td>\n",
       "      <td>0.668346</td>\n",
       "      <td>0.587374</td>\n",
       "      <td>0.186979</td>\n",
       "      <td>0.058372</td>\n",
       "      <td>0.594791</td>\n",
       "      <td>0.405209</td>\n",
       "      <td>0.941628</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.042791</td>\n",
       "      <td>0.702810</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.184179</td>\n",
       "      <td>0.063885</td>\n",
       "      <td>0.138032</td>\n",
       "      <td>0.071359</td>\n",
       "      <td>0.104696</td>\n",
       "      <td>0.864155</td>\n",
       "      <td>0.774324</td>\n",
       "      <td>0.611657</td>\n",
       "      <td>0.683445</td>\n",
       "      <td>0.605222</td>\n",
       "      <td>0.189384</td>\n",
       "      <td>0.056218</td>\n",
       "      <td>0.611657</td>\n",
       "      <td>0.388343</td>\n",
       "      <td>0.943782</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.049580</td>\n",
       "      <td>0.704688</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.196430</td>\n",
       "      <td>0.067135</td>\n",
       "      <td>0.145749</td>\n",
       "      <td>0.082776</td>\n",
       "      <td>0.114262</td>\n",
       "      <td>0.861801</td>\n",
       "      <td>0.752932</td>\n",
       "      <td>0.630444</td>\n",
       "      <td>0.686265</td>\n",
       "      <td>0.602416</td>\n",
       "      <td>0.200747</td>\n",
       "      <td>0.065239</td>\n",
       "      <td>0.630444</td>\n",
       "      <td>0.369556</td>\n",
       "      <td>0.934761</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.052571</td>\n",
       "      <td>0.711351</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.203385</td>\n",
       "      <td>0.010185</td>\n",
       "      <td>0.118353</td>\n",
       "      <td>0.086242</td>\n",
       "      <td>0.102298</td>\n",
       "      <td>0.865179</td>\n",
       "      <td>0.734661</td>\n",
       "      <td>0.685098</td>\n",
       "      <td>0.709015</td>\n",
       "      <td>0.622060</td>\n",
       "      <td>0.223576</td>\n",
       "      <td>0.078031</td>\n",
       "      <td>0.685098</td>\n",
       "      <td>0.314902</td>\n",
       "      <td>0.921969</td>\n",
       "      <td>19537.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.055012</td>\n",
       "      <td>0.764921</td>\n",
       "      <td>LGBM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    demographic parity  predictive parity  equality opportunity   \n",
       "0             0.011385           0.993243              0.037206  \\\n",
       "1             0.024310           0.996835              0.079727   \n",
       "2             0.038655           0.006873              0.091722   \n",
       "3             0.021673           0.000000              0.017922   \n",
       "4             0.028683           0.005814              0.031614   \n",
       "5             0.036005           0.002134              0.043393   \n",
       "6             0.057346           0.006960              0.008146   \n",
       "7             0.054103           0.001775              0.010189   \n",
       "8             0.068367           0.026821              0.017659   \n",
       "9             0.042162           0.006250              0.010208   \n",
       "10            0.048800           0.027780              0.052258   \n",
       "11            0.088155           0.049605              0.052525   \n",
       "12            0.091633           0.026325              0.054717   \n",
       "13            0.108260           0.043261              0.085268   \n",
       "14            0.120669           0.056145              0.092362   \n",
       "15            0.141611           0.086868              0.115178   \n",
       "16            0.164985           0.051462              0.133908   \n",
       "17            0.177417           0.018572              0.141384   \n",
       "18            0.178495           0.020057              0.142298   \n",
       "19            0.184179           0.063885              0.138032   \n",
       "20            0.196430           0.067135              0.145749   \n",
       "21            0.203385           0.010185              0.118353   \n",
       "\n",
       "    predictive equality  average absolute odds  accuracy  precision    recall   \n",
       "0              0.000111               0.018658  0.767723   0.993243  0.031383  \\\n",
       "1              0.000111               0.039919  0.776322   0.996835  0.067250   \n",
       "2              0.000442               0.046082  0.791677   0.993569  0.131939   \n",
       "3              0.000000               0.008961  0.784153   1.000000  0.099701   \n",
       "4              0.000332               0.015973  0.790039   0.994898  0.124893   \n",
       "5              0.000491               0.021942  0.796796   0.990385  0.153928   \n",
       "6              0.003117               0.005632  0.825869   0.969941  0.282451   \n",
       "7              0.002454               0.006322  0.822337   0.972720  0.266439   \n",
       "8              0.007795               0.012727  0.831448   0.942149  0.316396   \n",
       "9              0.001349               0.005778  0.812510   0.976657  0.223313   \n",
       "10             0.006592               0.029425  0.802631   0.923313  0.192784   \n",
       "11             0.015125               0.033825  0.839945   0.912560  0.367635   \n",
       "12             0.017479               0.036098  0.839689   0.890735  0.377669   \n",
       "13             0.023938               0.054603  0.846343   0.875782  0.418446   \n",
       "14             0.030163               0.061262  0.852024   0.861930  0.455807   \n",
       "15             0.044837               0.080007  0.854225   0.827156  0.495517   \n",
       "16             0.056247               0.095078  0.862210   0.799819  0.567250   \n",
       "17             0.067336               0.104360  0.858320   0.763476  0.592656   \n",
       "18             0.068109               0.105203  0.858474   0.762661  0.594791   \n",
       "19             0.071359               0.104696  0.864155   0.774324  0.611657   \n",
       "20             0.082776               0.114262  0.861801   0.752932  0.630444   \n",
       "21             0.086242               0.102298  0.865179   0.734661  0.685098   \n",
       "\n",
       "    f1 score       mcc  selection rate  false positive rate   \n",
       "0   0.060844  0.154197        0.007575             0.000067  \\\n",
       "1   0.126000  0.227375        0.016174             0.000067   \n",
       "2   0.232944  0.320185        0.031837             0.000269   \n",
       "3   0.181324  0.278665        0.023903             0.000000   \n",
       "4   0.221927  0.311580        0.030097             0.000202   \n",
       "5   0.266445  0.345902        0.037263             0.000471   \n",
       "6   0.437500  0.468568        0.069816             0.002760   \n",
       "7   0.418301  0.455159        0.065670             0.002356   \n",
       "8   0.473709  0.486843        0.080514             0.006127   \n",
       "9   0.363510  0.415684        0.054819             0.001683   \n",
       "10  0.318969  0.367547        0.050059             0.005049   \n",
       "11  0.524121  0.515286        0.096586             0.011109   \n",
       "12  0.530435  0.512923        0.101653             0.014610   \n",
       "13  0.566310  0.535847        0.114552             0.018717   \n",
       "14  0.596285  0.555305        0.126785             0.023026   \n",
       "15  0.619760  0.563461        0.143625             0.032653   \n",
       "16  0.663752  0.593780        0.170036             0.044772   \n",
       "17  0.667308  0.586606        0.186108             0.057901   \n",
       "18  0.668346  0.587374        0.186979             0.058372   \n",
       "19  0.683445  0.605222        0.189384             0.056218   \n",
       "20  0.686265  0.602416        0.200747             0.065239   \n",
       "21  0.709015  0.622060        0.223576             0.078031   \n",
       "\n",
       "    true positive rate  false negative rate  true negative rate    count   \n",
       "0             0.031383             0.968617            0.999933  19537.0  \\\n",
       "1             0.067250             0.932750            0.999933  19537.0   \n",
       "2             0.131939             0.868061            0.999731  19537.0   \n",
       "3             0.099701             0.900299            1.000000  19537.0   \n",
       "4             0.124893             0.875107            0.999798  19537.0   \n",
       "5             0.153928             0.846072            0.999529  19537.0   \n",
       "6             0.282451             0.717549            0.997240  19537.0   \n",
       "7             0.266439             0.733561            0.997644  19537.0   \n",
       "8             0.316396             0.683604            0.993873  19537.0   \n",
       "9             0.223313             0.776687            0.998317  19537.0   \n",
       "10            0.192784             0.807216            0.994951  19537.0   \n",
       "11            0.367635             0.632365            0.988891  19537.0   \n",
       "12            0.377669             0.622331            0.985390  19537.0   \n",
       "13            0.418446             0.581554            0.981283  19537.0   \n",
       "14            0.455807             0.544193            0.976974  19537.0   \n",
       "15            0.495517             0.504483            0.967347  19537.0   \n",
       "16            0.567250             0.432750            0.955228  19537.0   \n",
       "17            0.592656             0.407344            0.942099  19537.0   \n",
       "18            0.594791             0.405209            0.941628  19537.0   \n",
       "19            0.611657             0.388343            0.943782  19537.0   \n",
       "20            0.630444             0.369556            0.934761  19537.0   \n",
       "21            0.685098             0.314902            0.921969  19537.0   \n",
       "\n",
       "    best_trial  fair_metric  model_metric model_name  \n",
       "0            2     0.000000      0.052761         RF  \n",
       "1            1     0.000111      0.129615         RF  \n",
       "2            3     0.000219      0.211406         RF  \n",
       "3           17     0.000328      0.298484       LGBM  \n",
       "4            4     0.000726      0.392168       LGBM  \n",
       "5            5     0.000812      0.398623       LGBM  \n",
       "6           19     0.000948      0.417735       LGBM  \n",
       "7           20     0.001751      0.427776       LGBM  \n",
       "8           18     0.003929      0.471810       LGBM  \n",
       "9            7     0.004248      0.472184       LGBM  \n",
       "10           6     0.006572      0.493216       LGBM  \n",
       "11          12     0.006675      0.514874       LGBM  \n",
       "12          14     0.011271      0.539128       LGBM  \n",
       "13          15     0.016921      0.589778       LGBM  \n",
       "14           9     0.021963      0.618610       LGBM  \n",
       "15           8     0.039348      0.635345       LGBM  \n",
       "16          13     0.039683      0.667200       LGBM  \n",
       "17          21     0.041186      0.696462       LGBM  \n",
       "18          22     0.042791      0.702810       LGBM  \n",
       "19          10     0.049580      0.704688       LGBM  \n",
       "20          11     0.052571      0.711351       LGBM  \n",
       "21          16     0.055012      0.764921       LGBM  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['overall'].sort_values(['fair_metric']).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics[\u001b[39m'\u001b[39;49m\u001b[39mdefault_overall\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m df[\u001b[39m'\u001b[39;49m\u001b[39mmodel_name\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[0;32m~/miniconda3/envs/fairenv/lib/python3.10/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/miniconda3/envs/fairenv/lib/python3.10/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[0;32m~/miniconda3/envs/fairenv/lib/python3.10/site-packages/pandas/core/series.py:6086\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6083\u001b[0m res_name \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_op_result_name(\u001b[39mself\u001b[39m, other)\n\u001b[1;32m   6085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, Series) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indexed_same(other):\n\u001b[0;32m-> 6086\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only compare identically-labeled Series objects\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6088\u001b[0m lvalues \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[1;32m   6089\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    " metrics['default_overall']['model'] == df['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[39m=\u001b[39m metrics[\u001b[39m'\u001b[39m\u001b[39moverall\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mloc[metrics[\u001b[39m'\u001b[39m\u001b[39moverall\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mbest_trial \u001b[39m==\u001b[39m \u001b[39m5\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m n_model \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mmodel_name\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m metrics[\u001b[39m'\u001b[39;49m\u001b[39mdefault_overall\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[0;32m~/miniconda3/envs/fairenv/lib/python3.10/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/miniconda3/envs/fairenv/lib/python3.10/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__eq__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49meq)\n",
      "File \u001b[0;32m~/miniconda3/envs/fairenv/lib/python3.10/site-packages/pandas/core/series.py:6086\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6083\u001b[0m res_name \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_op_result_name(\u001b[39mself\u001b[39m, other)\n\u001b[1;32m   6085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, Series) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indexed_same(other):\n\u001b[0;32m-> 6086\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCan only compare identically-labeled Series objects\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6088\u001b[0m lvalues \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[1;32m   6089\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "    df = metrics['overall'].loc[metrics['overall'].best_trial == 5]\n",
    "    n_model = df['model_name'] == metrics['default_overall']['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    LGBM\n",
       "Name: model_name, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    LGBM\n",
       "Name: model_name, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['overall'].loc[metrics['overall'].best_trial == 5,'model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(0    False\n0    False\n0    False\n0    False\n0     True\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\nName: best_trial, dtype: bool, 'model_name')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/fairenv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/fairenv/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/fairenv/lib/python3.10/site-packages/pandas/_libs/index.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(0    False\n0    False\n0    False\n0    False\n0     True\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\nName: best_trial, dtype: bool, 'model_name')' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics[\u001b[39m'\u001b[39;49m\u001b[39moverall\u001b[39;49m\u001b[39m'\u001b[39;49m][metrics[\u001b[39m'\u001b[39;49m\u001b[39moverall\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mbest_trial \u001b[39m==\u001b[39;49m \u001b[39m5\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mmodel_name\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39m metrics[\u001b[39m'\u001b[39m\u001b[39mdefault_overall\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/fairenv/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/fairenv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3659\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3659\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[1;32m   3660\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fairenv/lib/python3.10/site-packages/pandas/core/indexes/base.py:5736\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5732\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m   5733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5734\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5735\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5736\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (0    False\n0    False\n0    False\n0    False\n0     True\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\n0    False\nName: best_trial, dtype: bool, 'model_name')"
     ]
    }
   ],
   "source": [
    "metrics['overall'][metrics['overall'].best_trial == 5,'model_name'] == metrics['default_overall']['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      RF\n",
       "0    LGBM\n",
       "Name: model, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['default_overall']['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Female\n",
       "1      Male\n",
       "Name: sex, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['bygroup'][metrics['bygroup'].best_trial == 1].iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "0    Female\n",
       "1      Male\n",
       "Name: sex, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['bygroup'].iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_groups_metrics(n, results_dict, model_mapping):\n",
    "    models = list(map(model_mapping.get,results_dict['models_sim_u'][0]))\n",
    "    #n_model = models.index(results_dict['models_sim'][0][n])\n",
    "\n",
    "    #df_groups_u = metrics['']\n",
    "    df_groups_u = results_dict['metrics_sim_u'][0][n_model].by_group.T\n",
    "    d = results_dict['metrics_sim_u'][0][n_model].difference()\n",
    "    d.name = 'Difference'\n",
    "    df_groups_u = pd.concat([df_groups_u,d], axis = 1).T\n",
    "    df_groups_u.columns = df_groups_u.columns + ' u'\n",
    "\n",
    "    df_groups_m = results_dict['metrics_sim'][0][n].by_group.T\n",
    "    d = results_dict['metrics_sim'][0][n].difference()\n",
    "    d.name = 'Difference'\n",
    "    df_groups_m = pd.concat([df_groups_m,d], axis = 1).T\n",
    "    df_groups = pd.concat([df_groups_u,df_groups_m],axis = 1).reset_index()\n",
    "    return df_groups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
