{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install fairlearn\n",
    "#! pip install lightgbm\n",
    "#! pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, cross_validate\n",
    "from fairlearn.metrics import (\n",
    "    count,\n",
    "    selection_rate,\n",
    "    equalized_odds_difference,\n",
    "    false_positive_rate,\n",
    "    false_negative_rate,\n",
    "    demographic_parity_difference\n",
    ")\n",
    "\n",
    "from fairlearn.datasets import fetch_adult\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azucena/miniconda3/envs/fairenv/lib/python3.10/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "data = fetch_adult(as_frame=True)\n",
    "X_raw = data.data\n",
    "y = (data.target == \">50K\") * 1\n",
    "A = X_raw[\"sex\"]\n",
    "\n",
    "(X_train, X_test, y_train, y_test, A_train, A_test) = train_test_split(\n",
    "    X_raw, y, A, test_size=0.3, random_state=12345, stratify=y\n",
    ")\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "A_train = A_train.reset_index(drop=True)\n",
    "A_test = A_test.reset_index(drop=True)\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"impute\", SimpleImputer()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer = Pipeline(\n",
    "    [\n",
    "        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            LGBMClassifier(n_jobs=-1),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_scorer(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    f1 = f1_score(y,y_pred)\n",
    "    abs_eod = np.abs(equalized_odds_difference(y, y_pred, sensitive_features=X['sex']))\n",
    "    return {'f1_score': f1, 'eod': abs_eod}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    lgbm_n_estimators = trial.suggest_int(\"lgbm_n_estimators\", 20, 10000)\n",
    "    lgbm_num_leaves = trial.suggest_int(\"lgbm_num_leaves\", 10, 1000)\n",
    "    lgbm_max_depth = trial.suggest_int(\"lgbm_max_depth\", 2, 20)\n",
    "    lgbm_min_child_samples = trial.suggest_int(\"lgbm_min_child_samples\", 5, 300)\n",
    "    lgbm_learning_rate = trial.suggest_float(\"lgbm_learning_rate\", .02, .5)\n",
    "    lgbm_boosting_type = trial.suggest_categorical(\"lgbm_boosting_type\", ['goss', 'gbdt'])\n",
    "\n",
    "\n",
    "    #model = LGBMClassifier(\n",
    "    #    n_estimators = lgbm_n_estimators,\n",
    "    #    num_leaves = lgbm_num_leaves,\n",
    "    #    max_depth = lgbm_max_depth,\n",
    "    #    min_child_samples = lgbm_min_child_samples,\n",
    "    #    learning_rate = lgbm_learning_rate,\n",
    "    #    boosting_type = lgbm_boosting_type,\n",
    "    #)\n",
    "    params = {\n",
    "        'n_estimators':lgbm_n_estimators,\n",
    "        'num_leaves':lgbm_num_leaves,\n",
    "        'max_depth':lgbm_max_depth,\n",
    "        'min_child_samples':lgbm_min_child_samples,\n",
    "        'learning_rate':lgbm_learning_rate,\n",
    "        'boosting_type':lgbm_boosting_type\n",
    "        }\n",
    "    pipeline['classifier'].set_params(**params)\n",
    "    #pipeline.steps.pop(1)\n",
    "    #pipeline.steps.insert(1,('classifier',model))\n",
    "\n",
    "    scores = cross_validate(\n",
    "            pipeline, \n",
    "            X_train,\n",
    "            y_train, \n",
    "            cv=5,\n",
    "            scoring=metric_scorer,\n",
    "            return_train_score=True)\n",
    "\n",
    "    fair_metric = scores['test_eod'].mean()\n",
    "    model_metric = scores['test_f1_score'].mean()\n",
    "\n",
    "    return fair_metric, model_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(directions=[\"minimize\", \"maximize\"],pruner=optuna.pruners.SuccessiveHalvingPruner())\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Number of finished trials: \", len(study.trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_pareto_front(study, target_names=[\"FLOPS\", \"accuracy\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
